httprr trace v1
326 1217
POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent HTTP/1.1
Host: generativelanguage.googleapis.com
User-Agent: geminiproxy.test/ (+https://astrophena.name/bleep-bloop)
Content-Length: 57
Content-Type: application/json

{"contents":[{"parts":[{"text":"Hello! How are you?"}]}]}HTTP/2.0 200 OK
Alt-Svc: h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
Content-Type: application/json; charset=UTF-8
Date: Sun, 17 Aug 2025 08:06:22 GMT
Server: scaffolding on HTTPServer2
Server-Timing: gfet4t7; dur=864
Vary: Origin
Vary: X-Origin
Vary: Referer
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 0

{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings in the same way humans do, but I am functioning optimally and ready to assist you. How can I help you today?\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.10347498893737793
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 6,
    "candidatesTokenCount": 50,
    "totalTokenCount": 56,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 6
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 50
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash",
  "responseId": "fY2haJ6LGaKMmNAPv4Kt0Aw"
}
